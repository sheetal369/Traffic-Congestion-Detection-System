{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4sMVI_2NAzdr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678330989479,"user_tz":-345,"elapsed":29758,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"}},"outputId":"05ead6ae-52be-4126-9c64-3ebab9e9e14b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17359,"status":"ok","timestamp":1678331006814,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"},"user_tz":-345},"id":"_Sp8S964yARl","outputId":"4c2f7a78-e3a7-4a54-b937-db9896e95354"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 1.13.1+cu116 (Tesla T4)\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt  # install dependencies\n","\n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","\n","clear_output()\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"markdown","metadata":{"id":"ccpQvXLlatKP"},"source":["Download pretrained yolov5 model\n","Choose one of the pretrained models from https://github.com/ultralytics/yolov5#inference\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4895,"status":"ok","timestamp":1675600785154,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"},"user_tz":-345},"id":"l5pTcJ1fyG5T","outputId":"6f2a19fb-ffe4-4955-b157-0b2f1c89c559"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-02-05 12:39:41--  https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230205T123941Z&X-Amz-Expires=300&X-Amz-Signature=87fa977419e913b0f23392cf739422de3586f7bb6e33b94cb5e57636ba848eaf&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-02-05 12:39:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230205%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230205T123941Z&X-Amz-Expires=300&X-Amz-Signature=87fa977419e913b0f23392cf739422de3586f7bb6e33b94cb5e57636ba848eaf&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14795158 (14M) [application/octet-stream]\n","Saving to: ‘yolov5s.pt’\n","\n","yolov5s.pt          100%[===================>]  14.11M  4.43MB/s    in 3.2s    \n","\n","2023-02-05 12:39:45 (4.43 MB/s) - ‘yolov5s.pt’ saved [14795158/14795158]\n","\n"]}],"source":["!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt"]},{"cell_type":"markdown","metadata":{"id":"wD1pTl7FuAVc"},"source":["# Train Vehicle Detection Model"]},{"cell_type":"code","source":["!python train.py --img 640 --batch 10  --epochs 100 --data ../gdrive/MyDrive/FYP_Sheetal/traffic_detection/configs/data.yaml --cfg models/yolov5s.yaml --cache "],"metadata":{"id":"JvXaJwb-Lojj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iPs4xXGW-DjD"},"source":["# Testing Detection Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CML-7VNysJSG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675618263440,"user_tz":-345,"elapsed":12548,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"}},"outputId":"25f5a9d8-2568-48ab-e1ef-3f01bdaa6cce"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/FYP_Sheetal/traffic_detection/trained_weights/best_prev.pt'], source=/content/gdrive/MyDrive/FYP_Sheetal/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-74-gd02ee60 Python-3.8.10 torch-1.13.1+cu116 CPU\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140420.jpg: 384x640 3 Cars, 3 Motorcycles, 125.0ms\n","image 2/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140422.jpg: 384x640 3 Cars, 2 Motorcycles, 1 Bus, 108.0ms\n","image 3/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140423.jpg: 384x640 4 Cars, 2 Motorcycles, 1 Bus, 115.3ms\n","image 4/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140424.jpg: 384x640 5 Cars, 5 Motorcycles, 1 Bus, 105.8ms\n","image 5/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140425.jpg: 384x640 3 Cars, 8 Motorcycles, 109.2ms\n","image 6/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140427.jpg: 384x640 4 Cars, 7 Motorcycles, 102.1ms\n","image 7/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140428.jpg: 384x640 3 Cars, 8 Motorcycles, 128.8ms\n","image 8/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140429.jpg: 384x640 3 Cars, 7 Motorcycles, 109.7ms\n","image 9/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140430.jpg: 384x640 2 Cars, 5 Motorcycles, 107.9ms\n","image 10/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140432.jpg: 384x640 2 Cars, 4 Motorcycles, 103.8ms\n","image 11/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140433.jpg: 384x640 4 Cars, 3 Motorcycles, 105.2ms\n","image 12/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140441.jpg: 384x640 8 Cars, 1 Motorcycle, 104.0ms\n","image 13/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140442.jpg: 384x640 7 Cars, 116.9ms\n","image 14/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140443.jpg: 384x640 5 Cars, 111.0ms\n","image 15/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140445.jpg: 384x640 5 Cars, 3 Motorcycles, 109.1ms\n","image 16/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140446.jpg: 384x640 6 Cars, 3 Motorcycles, 103.0ms\n","image 17/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140448.jpg: 384x640 2 Cars, 5 Motorcycles, 108.1ms\n","image 18/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140449.jpg: 384x640 4 Cars, 4 Motorcycles, 105.5ms\n","image 19/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140451.jpg: 384x640 4 Cars, 1 Motorcycle, 108.4ms\n","image 20/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140452.jpg: 384x640 3 Cars, 4 Motorcycles, 106.4ms\n","image 21/42 /content/gdrive/MyDrive/FYP_Sheetal/test/Copy of IMG_20230126_140453.jpg: 384x640 5 Cars, 2 Motorcycles, 102.6ms\n","image 22/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140420.jpg: 384x640 3 Cars, 3 Motorcycles, 102.8ms\n","image 23/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140422.jpg: 384x640 3 Cars, 2 Motorcycles, 1 Bus, 101.6ms\n","image 24/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140423.jpg: 384x640 4 Cars, 2 Motorcycles, 1 Bus, 107.4ms\n","image 25/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140424.jpg: 384x640 5 Cars, 5 Motorcycles, 1 Bus, 103.9ms\n","image 26/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140425.jpg: 384x640 3 Cars, 8 Motorcycles, 107.6ms\n","image 27/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140427.jpg: 384x640 4 Cars, 7 Motorcycles, 104.7ms\n","image 28/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140428.jpg: 384x640 3 Cars, 8 Motorcycles, 102.5ms\n","image 29/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140429.jpg: 384x640 3 Cars, 7 Motorcycles, 110.4ms\n","image 30/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140430.jpg: 384x640 2 Cars, 5 Motorcycles, 107.7ms\n","image 31/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140432.jpg: 384x640 2 Cars, 4 Motorcycles, 111.5ms\n","image 32/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140433.jpg: 384x640 4 Cars, 3 Motorcycles, 100.6ms\n","image 33/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140441.jpg: 384x640 8 Cars, 1 Motorcycle, 105.0ms\n","image 34/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140442.jpg: 384x640 7 Cars, 112.8ms\n","image 35/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140443.jpg: 384x640 5 Cars, 115.1ms\n","image 36/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140445.jpg: 384x640 5 Cars, 3 Motorcycles, 103.0ms\n","image 37/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140446.jpg: 384x640 6 Cars, 3 Motorcycles, 103.9ms\n","image 38/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140448.jpg: 384x640 2 Cars, 5 Motorcycles, 105.1ms\n","image 39/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140449.jpg: 384x640 4 Cars, 4 Motorcycles, 110.3ms\n","image 40/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140451.jpg: 384x640 4 Cars, 1 Motorcycle, 102.6ms\n","image 41/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140452.jpg: 384x640 3 Cars, 4 Motorcycles, 101.5ms\n","image 42/42 /content/gdrive/MyDrive/FYP_Sheetal/test/IMG_20230126_140453.jpg: 384x640 5 Cars, 2 Motorcycles, 101.3ms\n","Speed: 0.6ms pre-process, 107.6ms inference, 0.6ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n"]}],"source":["!python detect.py --weights /content/gdrive/MyDrive/FYP_Sheetal/traffic_detection/trained_weights/best_prev.pt --img 640 --conf 0.5 --source /content/gdrive/MyDrive/FYP_Sheetal/test/ --save --txt"]},{"cell_type":"code","source":["model = torch.hub.load('.', 'custom', path='/content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/models/best_with_changsin.pt', source='local') "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VQWM2YAqkfX8","executionInfo":{"status":"ok","timestamp":1678331049298,"user_tz":-345,"elapsed":27724,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"}},"outputId":"4f32168f-6284-4009-89d1-e0212b398d87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"setuptools>=65.5.1\" not found, attempting AutoUpdate...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.9/dist-packages (67.6.0)\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/yolov5/requirements.txt\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","YOLOv5 🚀 v7.0-117-g85f6019 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n","Adding AutoShape... \n"]}]},{"cell_type":"code","source":["model('/content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140410.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Onr1rL1gknU_","executionInfo":{"status":"ok","timestamp":1678306103147,"user_tz":-345,"elapsed":3229,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"}},"outputId":"360ff4e1-45ee-4f08-8569-4e1a73da485c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["YOLOv5 <class 'models.common.Detections'> instance\n","image 1/1: 1080x1920 7 Buss, 9 Cars, 14 Motorcycles\n","Speed: 723.8ms pre-process, 19.9ms inference, 51.4ms NMS per image at shape (1, 3, 384, 640)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeGM4abIWYZ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1678331151696,"user_tz":-345,"elapsed":45743,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"}},"outputId":"57c5c300-d1d5-43e6-8386-f613ac92681f"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/models/best_with_changsin.pt'], source=/content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 🚀 v7.0-117-g85f6019 Python-3.9.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7023610 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134650.jpg: 640x480 1 Bus, 10 Cars, 4 Motorcycles, 16.7ms\n","image 2/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134706.jpg: 640x480 6 Buss, 16 Cars, 16 Motorcycles, 9.9ms\n","image 3/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134726.jpg: 640x480 13 Cars, 10 Motorcycles, 9.9ms\n","image 4/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134740.jpg: 640x480 5 Buss, 4 Cars, 12 Motorcycles, 9.9ms\n","image 5/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134812.jpg: 640x480 16 Cars, 5 Motorcycles, 9.9ms\n","image 6/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134816.jpg: 640x480 10 Cars, 5 Motorcycles, 12.0ms\n","image 7/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_134846.jpg: 640x480 11 Buss, 19 Cars, 13 Motorcycles, 10.9ms\n","image 8/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_135846.jpg: 640x480 2 Buss, 7 Cars, 14 Motorcycles, 9.9ms\n","image 9/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_135856.jpg: 640x480 3 Buss, 7 Cars, 7 Motorcycles, 9.9ms\n","image 10/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_135900.jpg: 640x480 5 Buss, 6 Cars, 11 Motorcycles, 9.9ms\n","image 11/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_135912.jpg: 640x480 9 Buss, 7 Cars, 16 Motorcycles, 9.9ms\n","image 12/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_135921.jpg: 640x480 5 Buss, 9 Cars, 25 Motorcycles, 9.9ms\n","image 13/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140349.jpg: 384x640 2 Buss, 7 Cars, 7 Motorcycles, 13.0ms\n","image 14/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140354.jpg: 384x640 4 Buss, 6 Cars, 12 Motorcycles, 11.5ms\n","image 15/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140400.jpg: 384x640 8 Buss, 3 Cars, 16 Motorcycles, 11.1ms\n","image 16/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140405.jpg: 384x640 4 Buss, 4 Cars, 17 Motorcycles, 10.1ms\n","image 17/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140410.jpg: 384x640 5 Buss, 7 Cars, 11 Motorcycles, 8.7ms\n","image 18/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140413.jpg: 384x640 12 Motorcycles, 8.6ms\n","image 19/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140416.jpg: 384x640 5 Buss, 2 Cars, 10 Motorcycles, 8.7ms\n","image 20/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140420.jpg: 384x640 5 Buss, 1 Car, 10 Motorcycles, 8.6ms\n","image 21/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140427.jpg: 384x640 2 Buss, 4 Cars, 15 Motorcycles, 8.6ms\n","image 22/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140442.jpg: 384x640 4 Buss, 6 Cars, 7 Motorcycles, 8.6ms\n","image 23/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140456.jpg: 384x640 3 Buss, 3 Cars, 17 Motorcycles, 8.9ms\n","image 24/24 /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/IMG_20230126_140502.jpg: 384x640 2 Buss, 19 Motorcycles, 11.6ms\n","Speed: 0.6ms pre-process, 10.3ms inference, 2.6ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}],"source":["!python detect.py --weights /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/models/best_with_changsin.pt --img 640 --conf 0.5 --source /content/gdrive/MyDrive/FYP_Sheetal/streamlitApp/images/"]},{"cell_type":"markdown","metadata":{"id":"hL5gKdpA_VCg"},"source":["## Explanation of detection results\n","\n","1. results.names contain the names of classes: e.g., 'person'. There are 80 of them by default corresponding to 80 COCO dataset classes.\n","\n","  ['person',\n"," 'bicycle',\n"," 'car',\n"," 'motorcycle',\n"," 'airplane',\n"," 'bus',\n"," 'train',\n"," 'truck',\n"," 'boat',\n"," 'traffic light',\n"," 'fire hydrant',\n"," 'stop sign',\n"," 'parking meter',\n"," 'bench',\n"," 'bird',\n"," 'cat',\n"," 'dog',\n"," 'horse',\n"," 'sheep',\n"," 'cow',\n"," 'elephant',\n"," 'bear',\n"," 'zebra',\n"," 'giraffe',\n"," 'backpack',\n"," 'umbrella',\n"," 'handbag',\n"," 'tie',\n"," 'suitcase',\n"," 'frisbee',\n"," 'skis',\n"," 'snowboard',\n"," 'sports ball',\n"," 'kite',\n"," 'baseball bat',\n"," 'baseball glove',\n"," 'skateboard',\n"," 'surfboard',\n"," 'tennis racket',\n"," 'bottle',\n"," 'wine glass',\n"," 'cup',\n"," 'fork',\n"," 'knife',\n"," 'spoon',\n"," 'bowl',\n"," 'banana',\n"," 'apple',\n"," 'sandwich',\n"," 'orange',\n"," 'broccoli',\n"," 'carrot',\n"," 'hot dog',\n"," 'pizza',\n"," 'donut',\n"," 'cake',\n"," 'chair',\n"," 'couch',\n"," 'potted plant',\n"," 'bed',\n"," 'dining table',\n"," 'toilet',\n"," 'tv',\n"," 'laptop',\n"," 'mouse',\n"," 'remote',\n"," 'keyboard',\n"," 'cell phone',\n"," 'microwave',\n"," 'oven',\n"," 'toaster',\n"," 'sink',\n"," 'refrigerator',\n"," 'book',\n"," 'clock',\n"," 'vase',\n"," 'scissors',\n"," 'teddy bear',\n"," 'hair drier',\n"," 'toothbrush']\n"," \n","\n","2. results.xyxyn: xy coordinates followed by the confidence and the class id. For instance, the first item is class_id=0 with 90% confidence which refers to 'person' class\n","\n","```\n","[tensor([[ 0.73203,  0.43620,  0.85469,  0.88646,  0.90088,  0.00000],\n","         [ 0.70586,  0.36276,  0.92344,  0.49609,  0.62939, 25.00000],\n","         [ 0.58125,  0.40365,  0.73984,  0.78594,  0.46143, 77.00000],\n","         [ 0.39355,  0.15990,  0.58789,  0.80365,  0.44385, 10.00000],\n","         [ 0.19248,  0.50104,  0.20469,  0.54062,  0.29517,  0.00000]], device='cuda:0')]\n","```\n","results.xyxy and results.pred have the same content except in scientific notations.\n","```\n","[tensor([[1.75687e+03, 7.85156e+02, 2.05125e+03, 1.59562e+03, 9.00879e-01, 0.00000e+00],\n","         [1.69406e+03, 6.52969e+02, 2.21625e+03, 8.92969e+02, 6.29395e-01, 2.50000e+01],\n","         [1.39500e+03, 7.26562e+02, 1.77562e+03, 1.41469e+03, 4.61426e-01, 7.70000e+01],\n","         [9.44531e+02, 2.87812e+02, 1.41094e+03, 1.44656e+03, 4.43848e-01, 1.00000e+01],\n","         [4.61953e+02, 9.01875e+02, 4.91250e+02, 9.73125e+02, 2.95166e-01, 0.00000e+00]], device='cuda:0')]\n","```\n","3. results.imgs is the labeled image containing the detection results.\n","4. results.save('folder') saves the detection result image to the folder.\n"]},{"cell_type":"markdown","metadata":{"id":"7t5lmfBT_6jl"},"source":["With this information, we can now parse and count each vehicle type."]},{"cell_type":"markdown","metadata":{"id":"h8xTskHP5jAy"},"source":["## Plot annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPcjkcv9TClt"},"outputs":[],"source":["model_highway = yolov5.load('/content/DLTrafficCounter/models/yolov5s_highway.pt')\n","count_vehicles_total(model_highway, '/content/DLTrafficCounter/data/bbox_highway/test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MJnZzGK2bh6F"},"outputs":[],"source":["import glob\n","import os\n","\n","def glob_files(path, file_type=\"*\"):\n","    search_string = os.path.join(path, file_type)\n","    files = glob.glob(search_string)\n","\n","    # print('searching ', path)\n","    paths = []\n","    for f in files:\n","      if os.path.isdir(f):\n","        sub_paths = glob_files(f + '/')\n","        paths += sub_paths\n","      else:\n","        paths.append(f)\n","\n","    # We sort the images in alphabetical order to match them\n","    #  to the annotation files\n","    paths.sort()\n","    return paths\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBYlW6rjXytC"},"outputs":[],"source":["def count_vehicles_total(model, path, file_type=\"*.jpg\", confidence_threshold=0.5):\n","  filenames = glob_files(path, file_type=file_type)\n","  total_counts = dict()\n","  class_names = None\n","\n","  for filename in filenames:\n","    detection_res = model(filename)\n","    if not class_names:\n","      class_names = detection_res.names\n","\n","    counts = count_vehicles(detection_res,\n","                            confidence_threshold=confidence_threshold)\n","\n","    # print(os.path.basename(filename), counts)\n","    total_counts = add_dicts(total_counts, counts)\n","\n","  # print counts for each class name\n","  print(\"\\nTotal counts:\")\n","  print_class_counts(total_counts, class_names)\n","\n","  \n","\n","  return total_counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lrq0sGgoVrzs"},"outputs":[],"source":["def print_class_counts(dict1, class_names):\n","  # print counts for each class name\n","  for key, val in dict1.items():\n","    print(class_names[key], val)\n","\n","def count_vehicles(detection_res, confidence_threshold=0.5):\n","  counts = dict()\n","  # print(res.names.index('car'), res.names.index('bus'), res.names.index('truck'))\n","\n","  for pred in detection_res.xyxyn[0]:\n","    confidence = pred[-2]\n","    if confidence > confidence_threshold:\n","      # print(pred)\n","\n","      class_id = int(pred[-1])\n","      counts = dict_increment(counts, class_id)\n","\n","  print_class_counts(counts, detection_res.names)\n","  return counts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fJ_C0gh4TdbZ"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","IMAGE_SIZE = 600\n","\n","def load_images(path):\n","  files = glob_files(path, \"*.png\")\n","\n","  # print(files)\n","  X_data = []\n","  for file in files:\n","    image = cv2.imread(file)\n","    # print(image.shape)\n","    # x = cv2.resize(image, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n","\n","    X_data.append(image)\n","  return np.array(X_data)\n","\n","X_test = load_images(\"/content/gdrive/MyDrive/FYP_Sheetal/traffic_detection/dataset-vehicles/images/test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"im3rf-9oUBCI"},"outputs":[],"source":["WIDTH = 1920\n","HEIGHT = 1080\n","\n","def load_labels(path):\n","  files = glob_files(path, \"*.txt\")\n","\n","  Y_data = []\n","  for file in files:\n","    with open(file) as f:\n","      lines = f.readlines()\n","\n","      boxes = []\n","      for line in lines:\n","        tokens = line.split()\n","\n","        class_id = int(tokens[0])\n","        xc = float(tokens[1]) * WIDTH\n","        yc = float(tokens[2]) * HEIGHT\n","        width = float(tokens[3]) * WIDTH\n","        height = float(tokens[4]) * HEIGHT\n","\n","        boxes.append(np.array([class_id, xc, yc, width, height]))\n","        # print(class_id, xc, yc, width, height)\n","\n","      Y_data.append(np.array(boxes))\n","      # print(lines)\n","  return np.array(Y_data)\n","\n","Y_test = load_labels(\"/content/gdrive/MyDrive/FYP_Sheetal/traffic_detection/dataset-vehicles/labels/test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLVDsqz2WYHh"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","def create_patch_rectangle(y, color):\n","  # # in yolov5\n","  width = int(y[2])\n","  height = int(y[3])\n","  return patches.Rectangle((int(y[0] - width/2), int(y[1] - height/2)),\n","                           width, height,\n","                           edgecolor=color, fill=False)\n","\n","COLORS = [(0, 255/255, 0), (255/255, 255/255, 0), (255/255, 0, 0)]\n","\n","def plot_image(image, boxes, axis):\n","  # # print(boxes.shape)\n","  for box in boxes:\n","    # print(box)\n","    class_id = int(box[0])\n","    # print(type(class_id), class_id)\n","    rect = create_patch_rectangle(box[1:], COLORS[class_id])\n","    axis.add_patch(rect)\n","\n","  plt.imshow(image)\n","\n","def plot_images(X, Y, limit=10):\n","  fig = plt.figure(figsize=(100, 80))\n","\n","  last_id = min(limit, X.shape[0])\n","  for id in range(last_id):\n","    axis = fig.add_subplot(5, 3, id + 1)\n","    axis.get_xaxis().set_visible(False)\n","    axis.get_yaxis().set_visible(False)\n","    plot_image(X[id], Y[id], axis)\n","\n","plot_images(np.array([X_test[-1]]), np.array([Y_test[-1]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1675601145777,"user":{"displayName":"SHEETAL SHARMA","userId":"16836341467969990117"},"user_tz":-345},"id":"gfoGM3Tpl3vc","outputId":"8552afee-f40d-4f79-b1c2-d93d12715e41"},"outputs":[{"data":{"text/plain":["{'car': 3, 'bus': 2, 'truck': 2}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["def dict_increment(dict1, key):\n","  if key in dict1.keys():\n","    dict1[key] = dict1[key] + 1 \n","  else:\n","    dict1[key] = 1\n","\n","  return dict1\n","\n","def add_dicts(dict1, dict2):\n","  dict3 = dict()\n","\n","  for key1, val1 in dict1.items():\n","    dict3[key1] = val1\n","    if key1 in dict2.keys():\n","      dict3[key1] = val1 + dict2[key1]\n","\n","  for key2, val2 in dict2.items():\n","    if key2 not in dict1.keys():\n","      dict3[key2] = val2\n","\n","  return dict3\n","\n","dict1 = {}\n","\n","dict1 = dict_increment(dict1, 'car')\n","dict1 = dict_increment(dict1, 'car')\n","dict1 = dict_increment(dict1, 'bus')\n","dict1\n","\n","dict2 = {}\n","dict2 = dict_increment(dict2, 'car')\n","dict2 = dict_increment(dict2, 'bus')\n","dict2 = dict_increment(dict2, 'truck')\n","dict2 = dict_increment(dict2, 'truck')\n","dict2\n","\n","dict3 = add_dicts(dict1, dict2)\n","add_dicts(dict3, dict2)\n","add_dicts(dict1, dict2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhqiZy53VVaW"},"outputs":[],"source":["CLASSES = ['car', 'bus', 'truck']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aU9G7oQvwg0"},"outputs":[],"source":["def count_vehicles_in_annotations(Y):\n","  \"\"\"\n","  count vehicles in the annotations\n","  \"\"\"\n","\n","  total_counts = dict()\n","  for y in Y:\n","    counts = dict()\n","    for ann in y:\n","      counts = dict_increment(counts, int(ann[0]))\n","\n","    total_counts = add_dicts(total_counts, counts)\n","    # print(len(y), total_counts)\n","  print_class_counts(total_counts, CLASSES)\n","\n","count_vehicles_in_annotations(Y_test)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["wD1pTl7FuAVc"],"machine_shape":"hm","provenance":[{"file_id":"https://github.com/changsin/DLTrafficCounter/blob/main/notebooks/traffic_counter_yolov5.ipynb","timestamp":1674446235767}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}